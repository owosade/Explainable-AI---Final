{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPuJ35pd3kiOkdpZEnWJ2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owosade/Explainable-AI---Final/blob/main/Saliency_Map.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSb8KuEtARnD"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install torch torchvision captum\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from captum.attr import LayerGradCam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing fastai\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "#Importing all objects and functions from the fastai module\n",
        "from fastbook import *\n",
        "from fastai.vision.all import *\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from fastai.vision.all import *\n",
        "from torchvision import models, transforms\n",
        "from captum.attr import LayerGradCam\n",
        "\n",
        "\n",
        "\n",
        "#creating an object named \"Path\"\n",
        "path = Path('/content/gdrive/MyDrive/Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P62Ir022CDHa",
        "outputId": "84623a5d-9bff-42c1-a90d-74bd7f366496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_items = get_image_files(path/\"Test\")\n",
        "files= get_image_files(path)\n",
        "\n",
        "#data modification\n",
        "augumentations = [RandomResizedCropGPU(size=224, min_scale=0.75), Rotate(), Zoom()]\n",
        "\n",
        "#data block creation\n",
        "data_block = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock),\n",
        "                   splitter=GrandparentSplitter(train_name='Train', valid_name='Test'),\n",
        "                   get_y=parent_label,\n",
        "                   item_tfms=Resize(512, method=\"squish\"),\n",
        "                   batch_tfms=augumentations,\n",
        "                   )\n",
        "\n",
        "load_data_test = data_block.dataloaders(files)\n",
        "\n",
        "model = nn.Sequential(create_body(xresnet34(), pretrained=True),create_head(nf=2048, n_out=2))\n",
        "\n",
        "#Loading the saved model\n",
        "learn = cnn_learner(load_data_test, resnet34, metrics=accuracy).to_fp16()\n",
        "model = learn.load('/content/gdrive/MyDrive/Dataset/Final_project4')\n",
        "for name, module in model.named_modules():\n",
        "    print(name)\n",
        "\n",
        "for name, child in model.named_children():\n",
        "    print(name, child)\n",
        "\n",
        "# Find and print the last layer\n",
        "last_layer_name, last_layer = list(model.named_children())[-1]\n",
        "print(\"Last Layer:\", last_layer_name, last_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiMkzSyXsW3O",
        "outputId": "79ffd103-243e-4998-a327-e7919c4fe158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/vision/learner.py:301: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
            "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:03<00:00, 22.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0\n",
            "0.0\n",
            "0.1\n",
            "0.2\n",
            "0.3\n",
            "0.4\n",
            "0.4.0\n",
            "0.4.0.conv1\n",
            "0.4.0.bn1\n",
            "0.4.0.relu\n",
            "0.4.0.conv2\n",
            "0.4.0.bn2\n",
            "0.4.1\n",
            "0.4.1.conv1\n",
            "0.4.1.bn1\n",
            "0.4.1.relu\n",
            "0.4.1.conv2\n",
            "0.4.1.bn2\n",
            "0.4.2\n",
            "0.4.2.conv1\n",
            "0.4.2.bn1\n",
            "0.4.2.relu\n",
            "0.4.2.conv2\n",
            "0.4.2.bn2\n",
            "0.5\n",
            "0.5.0\n",
            "0.5.0.conv1\n",
            "0.5.0.bn1\n",
            "0.5.0.relu\n",
            "0.5.0.conv2\n",
            "0.5.0.bn2\n",
            "0.5.0.downsample\n",
            "0.5.0.downsample.0\n",
            "0.5.0.downsample.1\n",
            "0.5.1\n",
            "0.5.1.conv1\n",
            "0.5.1.bn1\n",
            "0.5.1.relu\n",
            "0.5.1.conv2\n",
            "0.5.1.bn2\n",
            "0.5.2\n",
            "0.5.2.conv1\n",
            "0.5.2.bn1\n",
            "0.5.2.relu\n",
            "0.5.2.conv2\n",
            "0.5.2.bn2\n",
            "0.5.3\n",
            "0.5.3.conv1\n",
            "0.5.3.bn1\n",
            "0.5.3.relu\n",
            "0.5.3.conv2\n",
            "0.5.3.bn2\n",
            "0.6\n",
            "0.6.0\n",
            "0.6.0.conv1\n",
            "0.6.0.bn1\n",
            "0.6.0.relu\n",
            "0.6.0.conv2\n",
            "0.6.0.bn2\n",
            "0.6.0.downsample\n",
            "0.6.0.downsample.0\n",
            "0.6.0.downsample.1\n",
            "0.6.1\n",
            "0.6.1.conv1\n",
            "0.6.1.bn1\n",
            "0.6.1.relu\n",
            "0.6.1.conv2\n",
            "0.6.1.bn2\n",
            "0.6.2\n",
            "0.6.2.conv1\n",
            "0.6.2.bn1\n",
            "0.6.2.relu\n",
            "0.6.2.conv2\n",
            "0.6.2.bn2\n",
            "0.6.3\n",
            "0.6.3.conv1\n",
            "0.6.3.bn1\n",
            "0.6.3.relu\n",
            "0.6.3.conv2\n",
            "0.6.3.bn2\n",
            "0.6.4\n",
            "0.6.4.conv1\n",
            "0.6.4.bn1\n",
            "0.6.4.relu\n",
            "0.6.4.conv2\n",
            "0.6.4.bn2\n",
            "0.6.5\n",
            "0.6.5.conv1\n",
            "0.6.5.bn1\n",
            "0.6.5.relu\n",
            "0.6.5.conv2\n",
            "0.6.5.bn2\n",
            "0.7\n",
            "0.7.0\n",
            "0.7.0.conv1\n",
            "0.7.0.bn1\n",
            "0.7.0.relu\n",
            "0.7.0.conv2\n",
            "0.7.0.bn2\n",
            "0.7.0.downsample\n",
            "0.7.0.downsample.0\n",
            "0.7.0.downsample.1\n",
            "0.7.1\n",
            "0.7.1.conv1\n",
            "0.7.1.bn1\n",
            "0.7.1.relu\n",
            "0.7.1.conv2\n",
            "0.7.1.bn2\n",
            "0.7.2\n",
            "0.7.2.conv1\n",
            "0.7.2.bn1\n",
            "0.7.2.relu\n",
            "0.7.2.conv2\n",
            "0.7.2.bn2\n",
            "1\n",
            "1.0\n",
            "1.0.ap\n",
            "1.0.mp\n",
            "1.1\n",
            "1.2\n",
            "1.3\n",
            "1.4\n",
            "1.5\n",
            "1.6\n",
            "1.7\n",
            "1.8\n",
            "0 Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "1 Sequential(\n",
            "  (0): AdaptiveConcatPool2d(\n",
            "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
            "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
            "  )\n",
            "  (1): fastai.layers.Flatten(full=False)\n",
            "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.25, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=512, bias=False)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): Dropout(p=0.5, inplace=False)\n",
            "  (8): Linear(in_features=512, out_features=2, bias=False)\n",
            ")\n",
            "Last Layer: 1 Sequential(\n",
            "  (0): AdaptiveConcatPool2d(\n",
            "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
            "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
            "  )\n",
            "  (1): fastai.layers.Flatten(full=False)\n",
            "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.25, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=512, bias=False)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): Dropout(p=0.5, inplace=False)\n",
            "  (8): Linear(in_features=512, out_features=2, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recursively get the last layer name\n",
        "def get_last_layer_name(module, prefix=''):\n",
        "    # Check if the module has sub-modules\n",
        "    if len(list(module.children())) > 0:\n",
        "        # Recursively call the function on the sub-modules\n",
        "        return get_last_layer_name(list(module.children())[-1], prefix + f\"{module.__class__.__name__}.\")\n",
        "    else:\n",
        "        # Return the name of the current module\n",
        "        return prefix + module.__class__.__name__\n",
        "\n",
        "# Get the last layer name using the function\n",
        "last_layer_name = get_last_layer_name(model)\n",
        "print(\"Last Layer Name:\", last_layer_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvHRuioXwCoE",
        "outputId": "0c217ab8-9742-4d16-eece-388dc0b1d894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last Layer Name: Learner.Sequential.Linear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'Learner.Sequential.Linear'\n",
        "layer = getattr(model, layer_name, None)\n",
        "if layer is not None:\n",
        "    # Register the forward hook on the chosen layer\n",
        "    hook_handle = layer.register_forward_hook(forward_hook)\n",
        "\n",
        "    # Perform a forward pass to trigger the hook\n",
        "    input_data = torch.randn(1, 3, 224, 224)  # Example input data\n",
        "    model(input_data)\n",
        "\n",
        "    # Remove the hook when done\n",
        "    hook_handle.remove()\n",
        "else:\n",
        "    print(f\"Layer '{layer_name}' not found in the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOILZfxtvXpn",
        "outputId": "266a68f8-3daf-4136-9f4d-ef71ac424522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 'Learner.Sequential.Linear' not found in the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "# Access the last layer in the model (assuming it's the head)\n",
        "last_layer = \"Learner.Sequential.Linear\"\n",
        "layer = getattr(model, last_layer, None)\n",
        "\n",
        "# Create a LayerGradCam object\n",
        "layer_grad_cam = LayerGradCam(learn.model, last_layer)\n",
        "\n",
        "\n",
        "# Choose an image from your dataset for generating saliency map\n",
        "image_path = '/content/gdrive/MyDrive/Dataset/Test/Kidney_stone/1.3.46.670589.33.1.63706830475347975400001.4676991400730475635.png'  # Replace with the actual path\n",
        "image = Image.open(image_path).convert('RGB')  # Ensure it's RGB\n",
        "\n",
        "# Preprocess the image\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_image = preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Generate the saliency map\n",
        "saliency_map = layer_grad_cam.attribute(input_image)\n",
        "\n",
        "# Visualize the original image and the saliency map\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Original image\n",
        "ax1.imshow(image)\n",
        "ax1.set_title('Original Image')\n",
        "\n",
        "# Saliency map\n",
        "ax2.imshow(saliency_map.squeeze().numpy(), cmap='hot')\n",
        "ax2.set_title('Saliency Map')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "hZwWoh0xKv8M",
        "outputId": "ca1b2c32-6c14-4aa1-a3ea-0e9cd8e6f960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'register_forward_hook'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6c57e75ee55f>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Generate the saliency map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msaliency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_grad_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Visualize the original image and the saliency map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/layer/grad_cam.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args, attribute_to_layer_input, relu_attributions, attr_dim_summation)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Returns gradient of output with respect to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# hidden layer and hidden layer evaluated at each input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         layer_gradients, layer_evals = compute_layer_gradients_and_eval(\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_layer_gradients_and_eval\u001b[0;34m(forward_fn, layer, inputs, target_ind, additional_forward_args, gradient_neuron_selector, device_ids, attribute_to_layer_input, output_fn)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# saved_layer is a dictionary mapping device to a tuple of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# layer evaluations on that device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         saved_layer, output = _forward_layer_distributed_eval(\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_distributed_eval\u001b[0;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return, require_layer_grads)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 all_hooks.append(\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0msingle_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                 )\n\u001b[1;32m    294\u001b[0m         output = _run_forward(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'register_forward_hook'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XfQIvDdhOGuX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}